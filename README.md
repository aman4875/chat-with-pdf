# ğŸ§  Chat with Your PDF â€“ FastAPI + LangChain + OpenAI

This project allows users to upload a PDF and chat with it using OpenAI's GPT models. It extracts, chunks, embeds, and stores your PDF content for semantic Q&A.

---

## ğŸš€ Features

- ğŸ“„ Upload any PDF file
- ğŸ§© Chunk and embed PDF content using OpenAI
- âš¡ Vector similarity search using FAISS
- ğŸ’¬ Ask questions and get accurate answers from the document
- ğŸ§  Built with FastAPI + LangChain
- ğŸ³ Dockerized for easy deployment

---

chat-with-pdf/
â”œâ”€â”€ main.py # FastAPI app entry point
â”œâ”€â”€ templates/
â”‚ â”œâ”€â”€ index.html # PDF upload UI
â”‚ â””â”€â”€ chat.html # Chat interface
â”œâ”€â”€ static/ # Static assets
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ Dockerfile # Docker configuration
â”œâ”€â”€ .env # OpenAI API key (not committed)
â””â”€â”€ README.md # You're here!



## ğŸ› ï¸ Tech Stack

| Layer        | Tool                                     |
|--------------|------------------------------------------|
| Backend      | FastAPI                                  |
| Embeddings   | OpenAI + LangChain                       |
| Vector Store | FAISS                                    |
| PDF Parsing  | PyPDFLoader (LangChain)                  |
| LLM          | OpenAI GPT-3.5-turbo or GPT-4            |
| Frontend     | Jinja2 templates                         |
| Deployment   | Docker + GitHub Actions (CI/CD)          |

---

## âš™ï¸ Getting Started

### 1. Clone the Repo

```bash
git clone https://github.com/<your-username>/chatbot_api.git
cd chatbot_api


python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

#Install Requirements

pip install -r requirements.txt

â–¶ï¸ Run the App

uvicorn main:app --reload

ğŸ³ Docker Deployment
1. Build Docker Image
docker build -t pdf-chat-app .

2. Run the Container
docker run -p 8000:8000 pdf-chat-app